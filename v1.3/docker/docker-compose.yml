x-bake:
  args:
    BUILDKIT_INLINE_CACHE: 1
  resources:
    memory: 10g  # Aligned with service limits
    swap: 2g
    cpus: 9
    cpu-quota: 900000

services:
  jupyter-cpu:
    build:
      context: ..
      dockerfile: docker/Dockerfile.cpu
      args:
        BUILDKIT_INLINE_CACHE: 1
        NB_UID: ${UID:-1000}
        NB_GID: ${GID:-1000}
      x-bake:
        platforms:
          - linux/amd64
        cache-from:
          - type=local,src=.buildx-cache
        cache-to:
          - type=local,dest=.buildx-cache
        resources:
          cpu-quota: 900000    # 9 CPUs (100000 = 1 CPU)
          memory: 10G          # Aligned with service limits
          swap: 2G             # 2GB swap
    image: bhumukulrajds/ds-workspace-cpu:1.3
    container_name: ds-workspace-cpu
    network_mode: bridge      # Changed from host for better security
    dns:                     # Added explicit DNS for better reliability
      - 8.8.8.8
      - 1.1.1.1
    userns_mode: "host"      # Enable user namespace remapping
    labels:
      maintainer: "bhumukulraj.ds@gmail.com"
      version: "1.3"          # Updated version
      description: "Data Science Development Environment - CPU Version"
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT:-4}'
          memory: ${CONTAINER_MEMORY_LIMIT:-10}G
          pids: 1000
          devices:
            - driver: cpu
              count: all
              capabilities: [cpu]
        reservations:
          cpus: '${CPU_RESERVATION:-2}'
          memory: ${CONTAINER_MEMORY_RESERVATION:-3}G
    ports:
      - "8888:8888"
    volumes:
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/projects
        target: /workspace/projects
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/datasets
        target: /workspace/datasets
        read_only: true      # Mark datasets as read-only
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/logs
        target: /workspace/logs
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/config/jupyter
        target: /home/ds-user-ds/.jupyter
    environment:
      - USE_GPU=false
      - TZ=${TZ:-UTC}
      - PYTHONGC=2          # Aggressive garbage collection
    logging:
      driver: "json-file"
      options:
        max-size: "50m"       # Reduced log size
        max-file: "5"         # Increased rotation
        compress: "true"      # Added compression
        tag: "{{.Name}}"
        format: "json"
    user: "${UID:-1000}:${GID:-1000}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8888/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    read_only: true        # Enable read-only root filesystem
    security_opt:
      - "no-new-privileges:true"
      - "apparmor:docker-default"
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID
      - NET_BIND_SERVICE

  jupyter-gpu:
    image: bhumukulrajds/ds-workspace-gpu:1.3
    build:
      context: ..
      dockerfile: docker/Dockerfile.gpu
      args:
        BUILDKIT_INLINE_CACHE: 1
        NB_UID: ${UID:-1000}
        NB_GID: ${GID:-1000}
      x-bake:
        platforms:
          - linux/amd64
        cache-from:
          - type=local,src=.buildx-cache
        cache-to:
          - type=local,dest=.buildx-cache
        resources:
          cpu-quota: 900000    # 9 CPUs (100000 = 1 CPU)
          memory: 10G          # Aligned with service limits
          swap: 2G             # 2GB swap
    container_name: ds-workspace-gpu
    runtime: nvidia
    shm_size: "2g"           # Added shared memory for CUDA operations
    network_mode: bridge     # Changed from host for better security
    dns:                    # Added explicit DNS for better reliability
      - 8.8.8.8
      - 1.1.1.1
    userns_mode: "host"     # Enable user namespace remapping
    labels:
      maintainer: "bhumukulraj.ds@gmail.com"
      version: "1.3"         # Updated version
      description: "Data Science Development Environment - GPU Version"
    deploy:
      resources:
        limits:
          cpus: '${CPU_LIMIT:-4}'
          memory: ${CONTAINER_MEMORY_LIMIT:-12}G
          pids: 1000
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        reservations:
          cpus: '${CPU_RESERVATION:-2}'
          memory: ${CONTAINER_MEMORY_RESERVATION:-4}G
    ports:
      - "8889:8888"          # JupyterLab on different port to avoid conflict
    volumes:
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/projects
        target: /workspace/projects
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/datasets
        target: /workspace/datasets
        read_only: true     # Mark datasets as read-only
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/logs
        target: /workspace/logs
      - /tmp/.X11-unix:/tmp/.X11-unix:ro  # For GUI applications
      - type: bind
        source: ${HOST_WORKSPACE_DIR}/config/jupyter
        target: /home/ds-user-ds/.jupyter
    environment:
      - USE_GPU=true
      - TZ=${TZ:-UTC}
      - PYTHONGC=2         # Aggressive garbage collection
      # GPU-specific environment variables
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-0}
      - NVIDIA_DRIVER_CAPABILITIES=${NVIDIA_DRIVER_CAPABILITIES:-compute,utility,graphics,display}
      - NVIDIA_REQUIRE_CUDA=${NVIDIA_REQUIRE_CUDA:-"cuda>=11.8"}
      - NVIDIA_MEM_MAX_PERCENT=${NVIDIA_MEM_MAX_PERCENT:-75}
      - NVIDIA_GPU_MEM_FRACTION=${NVIDIA_GPU_MEM_FRACTION:-0.6}  # Updated to use env variable
      - CUDA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-0}
      - DISPLAY=${DISPLAY:-:0}  # For GUI applications
      - QT_XCB_GL_INTEGRATION=none  # Fix for Qt error
    logging:
      driver: "json-file"
      options:
        max-size: "50m"      # Reduced log size
        max-file: "5"        # Increased rotation
        compress: "true"     # Added compression
        tag: "{{.Name}}"
        format: "json"
    user: "${UID:-1000}:${GID:-1000}"
    healthcheck:
      test: ["CMD-SHELL", "timeout 5 nvidia-smi >/dev/null 2>&1 && curl -f http://localhost:8888/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    read_only: true        # Enable read-only root filesystem
    security_opt:
      - "no-new-privileges:true"
      - "apparmor:docker-default"
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETUID
      - SETGID
      - NET_BIND_SERVICE

volumes:
  jupyter_logs_cpu:
    driver: local
  jupyter_logs_gpu:
    driver: local